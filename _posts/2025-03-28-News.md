---
title: 谷歌最强大模型登场，掀Agent风暴，放AI芯片大招，深夜突袭OpenAI  
description: 谷歌发布Gemini 2.0 Flash实验版本，速度是1.5 Pro的两倍，专为AI Agent时代设计，主打多模态+AI Agent。同时推出Trillium TPU芯片，性能显著提升。
date: 2025-03-28 10:00:00 +0800  
categories: [news]  
tags: [Information asymmetry today]  
---

# 谷歌最强大模型登场，掀Agent风暴，放AI芯片大招，深夜突袭OpenAI

**智东西 · 2024年12月12日 02:48**

其第一款新模型是Gemini 2.0 Flash的实验版本，速度是1.5 Pro的两倍。谷歌称，这款新模型专为AI Agent时代而设计，主打多模态+AI Agent。

基于Gemini 2.0 Flash，谷歌推出一大波AI Agent新品，包括今年5月轰动业界的通用AI助手原型Project Astra，还有能够作为实验性扩展在谷歌浏览器中完成多步骤复杂任务的Project Mariner，以及实验性AI编程Agent Jules、游戏Agent。

Gemini 2.0的发布，打响了迈向AI Agent新世界的关键一枪。

Gemini和Gemini Advanced用户可在桌面端的模型下拉菜单中选择聊天优化版Gemini 2.0来试用。开发人员可通过Google AI Studio和Vertex AI在Gemini API中开始使用此模型进行构建。

Gemini 2.0背后的核心硬件也正式揭晓——Trillium TPU。

## 01.Gemini 2.0首款模型发布！多模态输出、原生调用工具、四大Agent

在AI Agent方面，谷歌宣布了对实验性功能的更新，包括：
- 通用AI Agent Project Astra
- 多步骤任务AI Agent Project Mariner
- AI编程Agent Jules
- 游戏Agent

### 1、通用AI Agent Project Astra：记住10分钟视频，更强agent能力

由Gemini 2.0提供支持的Project Astra更新版本，可以实现Agent（代理）能力。其最新改进包括：

### 2、多步骤任务AI Agent Project Mariner：最佳工作结果83.5%，为保证安全目前需人类介入

Project Mariner是谷歌在Gemini 2.0模型基础上发布的一个实验性功能，其可以完成多步骤的复杂任务。

Jules可以解决问题、制定计划并执行它，所有过程都在开发人员的指导和监督下进行。在这一领域，谷歌的长期目标是构建在所有领域（包括编程）都有帮助的AI Agent。

谷歌发布了由Gemini 2.0提供支持的Project Astra更新版本的新演示视频。

Project Astra产品经理Bibo Xu说："它正在融合我们这个时代一些最强大的信息检索系统。"

Gemini 2.0的推理功能使其AI辅助红队方法取得重大进步，包括从简单地检测风险到自动生成评估和训练数据以减轻风险的能力。

通过Project Astra，谷歌正在探索针对用户无意中与代理共享敏感信息的潜在缓解措施，并且其已经内置了隐私控制功能，使用户可以轻松删除会话。他们还在继续研究以确保AI代理充当可靠的信息来源，并且不会代表您采取意外操作。

通过Project Mariner，谷歌正在努力确保模型学会优先考虑用户指令，而不是第三方的提示注入尝试，以便它可以识别来自外部来源的潜在恶意指令并防止滥用。这可以防止用户通过电子邮件、文档或网站中隐藏的恶意指令等方式受到欺诈和网络钓鱼攻击。

## 04.Gemini 2.0背后的硬件功臣：谷歌最强AI芯片Trillium TPU普遍可用

与前几代产品相比，Trillium TPU具有更好的扩展效率。下图表中，其测试展示了与同等规模的Cloud TPU v5p集群相比，Trillium在12 pod规模下的99%扩展效率（总峰值FLOPS）。

与Cloud TPU v5e相比，Trillium TPU提供了3倍的DRAM。在训练Llama-3.1-405B模型时，根据模型FLOPs利用率（MFU）测量，Trillium的主机卸载功能可将性能提高50%以上。

Trillium也为图像扩散模型和密集大语言模型提供了最佳的TPU推理性能。其测试表明，与Cloud TPU v5e相比，Stable Diffusion XL的相对推理吞吐量（每秒图像）提高了3倍以上，Llama2-70B的相对推理吞吐量（每秒token）提高了近2倍。

Trillium是谷歌在离线和服务器推理用例中性能最高的TPU。下图显示，与Cloud TPU v5e相比，Stable Diffusion XL的离线推理相对吞吐量（每秒图像数）提高了3.1倍，服务器推理相对吞吐量提高了2.9倍。

Trillium还旨在优化每美元的性能。迄今为止，在训练密集大语言模型（如Llama2-70b和Llama3.1-405b）中，Trillium的每美元性能比Cloud TPU v5e提高了2.1倍，比Cloud TPU v5p提高了2.5倍。

在Trillium上生成1000张图像的成本比离线推理的Cloud TPU v5e低27%，比在SDXL上进行服务器推理的Cloud TPU v5e低22%。

**来源**: [36氪](https://36kr.com/p/3075243697320835)